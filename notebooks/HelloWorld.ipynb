{"cells":[{"cell_type":"code","source":["print(\"Hello\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45f40cbc-7163-4b52-890a-60a3d1bde75a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Hello\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Hello\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# driver program\ndata = [10,20,30,40] # data, list\n# sc.<<TAB>>\nrdd = sc.parallelize(data) # distribute the data across cluster\n# max - action function, it get results, create task, execute task on workers, get the result\nprint(rdd.max())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6a176d3-7610-4329-94c6-2fd4dfeff701"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">40\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">40\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["data = [1,2,3,4,5,6,7,8,9,10]\n# RDDs are immutable\nrdd = sc.parallelize(data) # data input, lazy won't run until action called\n\nrdd2 = rdd.map (lambda n: n * 3) # tranformation, lazy, , lazy won't run until action called\n\nrdd3 = rdd2.filter (lambda n: n % 2 == 0) # transform, take only even numbers, ignore odd number\n\n# collect data to driver.. NOT LAZY method like transform.\n# action 1, job 1\nresult = rdd.collect() # action method, create job, task, stages, DAG, run the tasks on worker, finally get result\n\n# collect result of rdd2 which is multipling each number by 3\nprint(result)\n\n# action 2, job 2\nresult2 = rdd2.collect()  # action, perform and run transformation, task....\n\nprint(result2)\n\nprint(rdd2.toDebugString())\n\nprint (rdd3.collect()) # action, even numbers\n\nprint(rdd3.toDebugString())\n\n# string with \"\"\" means here you can write multiline text, also comments \"\"\"\n\"\"\"\nTop to Bottom\n  rdd \n    - rdd2\n        - rdd3\n \n\"\"\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f6c4f10-45ba-4442-8c01-2f0288dc50da"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\nb&#39;(8) PythonRDD[15] at collect at &lt;command-4158140795229798&gt;:17 []\\n |  ParallelCollectionRDD[14] at readRDDFromFile at PythonRDD.scala:332 []&#39;\n[6, 12, 18, 24, 30]\nb&#39;(8) PythonRDD[16] at collect at &lt;command-4158140795229798&gt;:23 []\\n |  ParallelCollectionRDD[14] at readRDDFromFile at PythonRDD.scala:332 []&#39;\nOut[10]: &#39;\\nTop to Bottom\\n  rdd \\n    - rdd2\\n        - rdd3\\n \\n&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\nb&#39;(8) PythonRDD[15] at collect at &lt;command-4158140795229798&gt;:17 []\\n |  ParallelCollectionRDD[14] at readRDDFromFile at PythonRDD.scala:332 []&#39;\n[6, 12, 18, 24, 30]\nb&#39;(8) PythonRDD[16] at collect at &lt;command-4158140795229798&gt;:23 []\\n |  ParallelCollectionRDD[14] at readRDDFromFile at PythonRDD.scala:332 []&#39;\nOut[10]: &#39;\\nTop to Bottom\\n  rdd \\n    - rdd2\\n        - rdd3\\n \\n&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# is rdd processing data from begining or not... - Yes\ndata = [1,2,3]\n\nrdd = sc.parallelize(data)\n\n# run on worker, lmabda with map (lambda n : n * 3) run on cluster/worker\ndef multiply(n):\n  print (n, \"*\", 3, \"called\")\n  return n * 3\n\ndef filterEven(n):\n  print (n, \"%\", 2, \"fillter called\")\n  return n  % 2 == 0\n\n# multiply, lambda, are run inside spark cluster, not on the spark driver\n# print output goes background\nrdd2 = rdd.map (multiply) #  NO TASK, No Partitions, no memory created\n# run on driver\nrdd3 = rdd2.filter (filterEven)   #  NO TASK, No Partitions, no memory created\n\nrdd4 = rdd.map (lambda n : n * 4)\n\n\n# rdd3.collect()\n# run on driver\nprint(rdd3.collect()) # calling action on rdd first time, sync call, creation memory, tasks\n#print(rdd3.collect()) # calling action on rdd second time\n \nprint(rdd3.min()) # action\nprint(rdd3.max()) # action"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30109d1c-f514-42fd-8102-dc9136e75d08"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[6]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[6]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Default partitions\ndata = [1,2,3,4,5,6]\n\nrdd = sc.parallelize(data)\n\nprint(sc.defaultMinPartitions) # default partition given as 2\nprint(sc.defaultParallelism) # 8 parallel tasks can be performed\n\nprint(\"rdd parts \", rdd.getNumPartitions())\n\nprint (\"partitiion data\")\n\n# colelct() collect data from all paritions and club them together\n\n# glom() this collect data from individual paritions, bring them as is\n# glom() returning an rdd which is partition specific? method\npartData = rdd.glom().collect()\nfor d in partData:\n  print (d)\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20264a32-b136-4b91-981f-70d3188fabb0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2\n8\nrdd parts  8\npartitiion data\n[]\n[1]\n[2]\n[3]\n[]\n[4]\n[5]\n[6]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2\n8\nrdd parts  8\npartitiion data\n[]\n[1]\n[2]\n[3]\n[]\n[4]\n[5]\n[6]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# limit paritions during input stage\n\ndata = [1,2,3,4,5,6]\n\nrdd = sc.parallelize(data, 4)\n\nprint(\"rdd parts \", rdd.getNumPartitions())\n\nprint (\"partitiion data\")\n\n# colelct() collect data from all paritions and club them together\n\n# glom() this collect data from individual paritions, bring them as is\n# glom() returning an rdd which is partition specific? method\npartData = rdd.glom().collect()\nfor d in partData:\n  print (d)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"458a0eb9-d8af-49e5-9885-e448d7fe485e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">rdd parts  4\npartitiion data\n[1]\n[2, 3]\n[4]\n[5, 6]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">rdd parts  4\npartitiion data\n[1]\n[2, 3]\n[4]\n[5, 6]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# limit paritions using reparition\n\ndata = [1,2,3,4,5,6]\n\nrdd = sc.parallelize(data)\n\nprint(\"rdd parts \", rdd.getNumPartitions()) # 8\n\nprint (\"rdd partitiion data\")\n\n# colelct() collect data from all paritions and club them together\n\n# glom() this collect data from individual paritions, bring them as is\n# glom() returning an rdd which is partition specific? method\npartData = rdd.glom().collect()\nfor d in partData:\n  print (d)\n  \n\n# reduce the paritions into 2, all data from rdd's 8 paritions, here filled in two paritions\nrdd2 = rdd.repartition(2)\nprint(\"rdd2 parts \", rdd2.getNumPartitions()) # 2\n\nprint (\"rdd2 partitiion data\")\npartData = rdd2.glom().collect()\nfor d in partData:\n  print (d)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f178788f-c163-4e2a-801d-61af33230b88"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">rdd parts  8\nrdd partitiion data\n[]\n[1]\n[2]\n[3]\n[]\n[4]\n[5]\n[6]\nrdd2 parts  2\nrdd2 partitiion data\n[2, 3, 5]\n[1, 4, 6]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">rdd parts  8\nrdd partitiion data\n[]\n[1]\n[2]\n[3]\n[]\n[4]\n[5]\n[6]\nrdd2 parts  2\nrdd2 partitiion data\n[2, 3, 5]\n[1, 4, 6]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# 4 core cpus, If HT enabled, split into 8 logical cores, v.cores\n# number of v.cores = 8\n\n# IO - read csv - Disk IO, Network IO, Hadoop, S3, Latency\n# RAM speed slower than CPU - IO\n\n# Parallel Tasks = v.cores * 2 or 3 times \n\n# community edition 2 v.cores * 4 = 8 parallel tasks"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0737fcdb-8478-4b25-ba43-489cfe4c7b35"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# RDD Cache\n# is rdd processing data from begining or not... - Yes\ndata = [1,2,3]\n\nrdd = sc.parallelize(data)\n\n# run on worker, lmabda with map (lambda n : n * 3) run on cluster/worker\ndef multiply(n):\n  print (n, \"*\", 3, \"called\")\n  return n * 3\n\ndef filterEven(n):\n  print (n, \"%\", 2, \"fillter called\")\n  return n  % 2 == 0\n\nrdd2 = rdd.map (multiply) \n\n# cache internally calls persist function with MEMORY_AND_DISK\nrdd2.cache() # Lazy, when called with action, the partition data is cached in worker\nprint(\"is_cached\", rdd2.is_cached)\n\nrdd3 = rdd2.filter (filterEven)   \nrdd4 = rdd3.map (lambda n : n * 4)\n\n# run on driver\nprint(rdd4.collect()) # calling action on rdd first time, sync call, \nprint(rdd3.min()) # action\nprint(rdd3.max()) # action\n\nrdd2.unpersist() # clear the cache\n# sc.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8001116-efcb-4e85-a286-5ba5f355587e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">is_cached True\n[24]\n6\n6\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">is_cached True\n[24]\n6\n6\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16724756-f1cb-4406-b7ba-0f856d1638aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"HelloWorld","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4158140795229795}},"nbformat":4,"nbformat_minor":0}
